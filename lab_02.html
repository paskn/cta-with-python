<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Lab 02: Words as data points II – Computational Text Analysis with Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-960d9d362f81d399278ec3e29b622b37.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Computational Text Analysis with Python</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./basic-python.html"> 
<span class="menu-text">Python Basics</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives"><span class="header-section-number">1</span> Learning objectives</a></li>
  <li><a href="#introduction-why-compare-corpora" id="toc-introduction-why-compare-corpora" class="nav-link" data-scroll-target="#introduction-why-compare-corpora"><span class="header-section-number">2</span> Introduction: Why compare corpora?</a>
  <ul>
  <li><a href="#the-research-question" id="toc-the-research-question" class="nav-link" data-scroll-target="#the-research-question"><span class="header-section-number">2.1</span> The research question</a></li>
  <li><a href="#our-approach-today" id="toc-our-approach-today" class="nav-link" data-scroll-target="#our-approach-today"><span class="header-section-number">2.2</span> Our approach today</a></li>
  </ul></li>
  <li><a href="#setup-loading-packages" id="toc-setup-loading-packages" class="nav-link" data-scroll-target="#setup-loading-packages"><span class="header-section-number">3</span> Setup: Loading packages</a>
  <ul>
  <li><a href="#loading-spacy-model" id="toc-loading-spacy-model" class="nav-link" data-scroll-target="#loading-spacy-model"><span class="header-section-number">3.1</span> Loading spaCy model</a></li>
  </ul></li>
  <li><a href="#loading-and-preparing-the-data" id="toc-loading-and-preparing-the-data" class="nav-link" data-scroll-target="#loading-and-preparing-the-data"><span class="header-section-number">4</span> Loading and preparing the data</a>
  <ul>
  <li><a href="#creating-contrasting-corpora" id="toc-creating-contrasting-corpora" class="nav-link" data-scroll-target="#creating-contrasting-corpora"><span class="header-section-number">4.1</span> Creating contrasting corpora</a></li>
  <li><a href="#combining-texts-by-party" id="toc-combining-texts-by-party" class="nav-link" data-scroll-target="#combining-texts-by-party"><span class="header-section-number">4.2</span> Combining texts by party</a></li>
  </ul></li>
  <li><a href="#from-wordforms-to-lemmas-introduction-to-lemmatization" id="toc-from-wordforms-to-lemmas-introduction-to-lemmatization" class="nav-link" data-scroll-target="#from-wordforms-to-lemmas-introduction-to-lemmatization"><span class="header-section-number">5</span> From wordforms to lemmas: Introduction to lemmatization</a>
  <ul>
  <li><a href="#the-problem-with-raw-words" id="toc-the-problem-with-raw-words" class="nav-link" data-scroll-target="#the-problem-with-raw-words"><span class="header-section-number">5.1</span> The problem with raw words</a></li>
  <li><a href="#two-solutions-stemming-vs-lemmatization" id="toc-two-solutions-stemming-vs-lemmatization" class="nav-link" data-scroll-target="#two-solutions-stemming-vs-lemmatization"><span class="header-section-number">5.2</span> Two solutions: Stemming vs lemmatization</a></li>
  <li><a href="#how-lemmatization-works" id="toc-how-lemmatization-works" class="nav-link" data-scroll-target="#how-lemmatization-works"><span class="header-section-number">5.3</span> How lemmatization works</a></li>
  <li><a href="#lemmatization-with-spacy" id="toc-lemmatization-with-spacy" class="nav-link" data-scroll-target="#lemmatization-with-spacy"><span class="header-section-number">5.4</span> Lemmatization with spaCy</a></li>
  </ul></li>
  <li><a href="#processing-our-corpora-with-spacy" id="toc-processing-our-corpora-with-spacy" class="nav-link" data-scroll-target="#processing-our-corpora-with-spacy"><span class="header-section-number">6</span> Processing our corpora with spaCy</a>
  <ul>
  <li><a href="#extracting-lemmas-and-filtering" id="toc-extracting-lemmas-and-filtering" class="nav-link" data-scroll-target="#extracting-lemmas-and-filtering"><span class="header-section-number">6.1</span> Extracting lemmas and filtering</a></li>
  <li><a href="#creating-frequency-tables" id="toc-creating-frequency-tables" class="nav-link" data-scroll-target="#creating-frequency-tables"><span class="header-section-number">6.2</span> Creating frequency tables</a></li>
  </ul></li>
  <li><a href="#the-problem-with-simple-frequency-comparisons" id="toc-the-problem-with-simple-frequency-comparisons" class="nav-link" data-scroll-target="#the-problem-with-simple-frequency-comparisons"><span class="header-section-number">7</span> The problem with simple frequency comparisons</a>
  <ul>
  <li><a href="#corpus-size-matters" id="toc-corpus-size-matters" class="nav-link" data-scroll-target="#corpus-size-matters"><span class="header-section-number">7.1</span> Corpus size matters</a></li>
  <li><a href="#example-the-word-people" id="toc-example-the-word-people" class="nav-link" data-scroll-target="#example-the-word-people"><span class="header-section-number">7.2</span> Example: The word “people”</a></li>
  <li><a href="#two-questions-we-need-to-answer" id="toc-two-questions-we-need-to-answer" class="nav-link" data-scroll-target="#two-questions-we-need-to-answer"><span class="header-section-number">7.3</span> Two questions we need to answer</a></li>
  </ul></li>
  <li><a href="#measuring-significance-log-likelihood-g²" id="toc-measuring-significance-log-likelihood-g²" class="nav-link" data-scroll-target="#measuring-significance-log-likelihood-g²"><span class="header-section-number">8</span> Measuring significance: Log-likelihood (G²)</a>
  <ul>
  <li><a href="#the-problem-when-is-a-difference-real" id="toc-the-problem-when-is-a-difference-real" class="nav-link" data-scroll-target="#the-problem-when-is-a-difference-real"><span class="header-section-number">8.1</span> The problem: When is a difference real?</a></li>
  <li><a href="#what-is-log-likelihood-g²" id="toc-what-is-log-likelihood-g²" class="nav-link" data-scroll-target="#what-is-log-likelihood-g²"><span class="header-section-number">8.2</span> What is log-likelihood (G²)?</a></li>
  <li><a href="#how-to-read-g²-values" id="toc-how-to-read-g²-values" class="nav-link" data-scroll-target="#how-to-read-g²-values"><span class="header-section-number">8.3</span> How to read G² values</a></li>
  <li><a href="#calculating-g²-in-python" id="toc-calculating-g²-in-python" class="nav-link" data-scroll-target="#calculating-g²-in-python"><span class="header-section-number">8.4</span> Calculating G² in Python</a></li>
  <li><a href="#using-g²-to-find-significant-differences" id="toc-using-g²-to-find-significant-differences" class="nav-link" data-scroll-target="#using-g²-to-find-significant-differences"><span class="header-section-number">8.5</span> Using G² to find significant differences</a></li>
  <li><a href="#how-many-significant-differences-did-we-find" id="toc-how-many-significant-differences-did-we-find" class="nav-link" data-scroll-target="#how-many-significant-differences-did-we-find"><span class="header-section-number">8.6</span> How many significant differences did we find?</a></li>
  <li><a href="#the-problem-stop-words-dominate" id="toc-the-problem-stop-words-dominate" class="nav-link" data-scroll-target="#the-problem-stop-words-dominate"><span class="header-section-number">8.7</span> The problem: Stop words dominate</a></li>
  <li><a href="#what-g²-doesnt-tell-us" id="toc-what-g²-doesnt-tell-us" class="nav-link" data-scroll-target="#what-g²-doesnt-tell-us"><span class="header-section-number">8.8</span> What G² doesn’t tell us</a></li>
  </ul></li>
  <li><a href="#measuring-effect-size-log-odds-ratio" id="toc-measuring-effect-size-log-odds-ratio" class="nav-link" data-scroll-target="#measuring-effect-size-log-odds-ratio"><span class="header-section-number">9</span> Measuring effect size: Log odds ratio</a>
  <ul>
  <li><a href="#the-problem-g²-doesnt-tell-us-everything" id="toc-the-problem-g²-doesnt-tell-us-everything" class="nav-link" data-scroll-target="#the-problem-g²-doesnt-tell-us-everything"><span class="header-section-number">9.1</span> The problem: G² doesn’t tell us everything</a></li>
  <li><a href="#what-is-log-odds-ratio" id="toc-what-is-log-odds-ratio" class="nav-link" data-scroll-target="#what-is-log-odds-ratio"><span class="header-section-number">9.2</span> What is log odds ratio?</a></li>
  <li><a href="#how-to-read-log-odds-values" id="toc-how-to-read-log-odds-values" class="nav-link" data-scroll-target="#how-to-read-log-odds-values"><span class="header-section-number">9.3</span> How to read log odds values</a></li>
  <li><a href="#a-concrete-example" id="toc-a-concrete-example" class="nav-link" data-scroll-target="#a-concrete-example"><span class="header-section-number">9.4</span> A concrete example</a></li>
  <li><a href="#calculating-log-odds-ratio-in-python" id="toc-calculating-log-odds-ratio-in-python" class="nav-link" data-scroll-target="#calculating-log-odds-ratio-in-python"><span class="header-section-number">9.5</span> Calculating log odds ratio in Python</a></li>
  <li><a href="#using-log-odds-ratio-to-see-which-party-uses-each-word" id="toc-using-log-odds-ratio-to-see-which-party-uses-each-word" class="nav-link" data-scroll-target="#using-log-odds-ratio-to-see-which-party-uses-each-word"><span class="header-section-number">9.6</span> Using log odds ratio to see which party uses each word</a></li>
  <li><a href="#reading-the-results-putting-it-all-together" id="toc-reading-the-results-putting-it-all-together" class="nav-link" data-scroll-target="#reading-the-results-putting-it-all-together"><span class="header-section-number">9.7</span> Reading the results: Putting it all together</a></li>
  <li><a href="#finding-the-most-meaningful-differences" id="toc-finding-the-most-meaningful-differences" class="nav-link" data-scroll-target="#finding-the-most-meaningful-differences"><span class="header-section-number">9.8</span> Finding the most meaningful differences</a></li>
  </ul></li>
  <li><a href="#visualizing-differences" id="toc-visualizing-differences" class="nav-link" data-scroll-target="#visualizing-differences"><span class="header-section-number">10</span> Visualizing differences</a>
  <ul>
  <li><a href="#bar-chart-of-log-odds-ratios" id="toc-bar-chart-of-log-odds-ratios" class="nav-link" data-scroll-target="#bar-chart-of-log-odds-ratios"><span class="header-section-number">10.1</span> Bar chart of log odds ratios</a></li>
  <li><a href="#scatter-plot-significance-vs-effect-size" id="toc-scatter-plot-significance-vs-effect-size" class="nav-link" data-scroll-target="#scatter-plot-significance-vs-effect-size"><span class="header-section-number">10.2</span> Scatter plot: Significance vs effect size</a></li>
  </ul></li>
  <li><a href="#named-entity-recognition" id="toc-named-entity-recognition" class="nav-link" data-scroll-target="#named-entity-recognition"><span class="header-section-number">11</span> Named entity recognition</a>
  <ul>
  <li><a href="#how-ner-works" id="toc-how-ner-works" class="nav-link" data-scroll-target="#how-ner-works"><span class="header-section-number">11.1</span> How NER works</a></li>
  <li><a href="#extracting-entities-with-spacy" id="toc-extracting-entities-with-spacy" class="nav-link" data-scroll-target="#extracting-entities-with-spacy"><span class="header-section-number">11.2</span> Extracting entities with spaCy</a></li>
  <li><a href="#comparing-entity-usage-across-parties" id="toc-comparing-entity-usage-across-parties" class="nav-link" data-scroll-target="#comparing-entity-usage-across-parties"><span class="header-section-number">11.3</span> Comparing entity usage across parties</a></li>
  <li><a href="#statistical-comparison-of-locations" id="toc-statistical-comparison-of-locations" class="nav-link" data-scroll-target="#statistical-comparison-of-locations"><span class="header-section-number">11.4</span> Statistical comparison of locations</a></li>
  <li><a href="#visualizing-location-mentions" id="toc-visualizing-location-mentions" class="nav-link" data-scroll-target="#visualizing-location-mentions"><span class="header-section-number">11.5</span> Visualizing location mentions</a></li>
  </ul></li>
  <li><a href="#summary-and-key-takeaways" id="toc-summary-and-key-takeaways" class="nav-link" data-scroll-target="#summary-and-key-takeaways"><span class="header-section-number">12</span> Summary and key takeaways</a>
  <ul>
  <li><a href="#what-we-learned" id="toc-what-we-learned" class="nav-link" data-scroll-target="#what-we-learned"><span class="header-section-number">12.1</span> What we learned</a></li>
  <li><a href="#key-concepts" id="toc-key-concepts" class="nav-link" data-scroll-target="#key-concepts"><span class="header-section-number">12.2</span> Key concepts</a></li>
  <li><a href="#critical-insights" id="toc-critical-insights" class="nav-link" data-scroll-target="#critical-insights"><span class="header-section-number">12.3</span> Critical insights</a></li>
  <li><a href="#statistical-comparison-workflow" id="toc-statistical-comparison-workflow" class="nav-link" data-scroll-target="#statistical-comparison-workflow"><span class="header-section-number">12.4</span> Statistical comparison workflow</a></li>
  </ul></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">13</span> Exercises</a>
  <ul>
  <li><a href="#exercise-1-full-corpus-analysis" id="toc-exercise-1-full-corpus-analysis" class="nav-link" data-scroll-target="#exercise-1-full-corpus-analysis"><span class="header-section-number">13.1</span> Exercise 1: Full corpus analysis</a></li>
  <li><a href="#exercise-2-stop-word-investigation" id="toc-exercise-2-stop-word-investigation" class="nav-link" data-scroll-target="#exercise-2-stop-word-investigation"><span class="header-section-number">13.2</span> Exercise 2: Stop word investigation</a></li>
  <li><a href="#exercise-3-temporal-comparison" id="toc-exercise-3-temporal-comparison" class="nav-link" data-scroll-target="#exercise-3-temporal-comparison"><span class="header-section-number">13.3</span> Exercise 3: Temporal comparison</a></li>
  <li><a href="#exercise-4-named-entity-deep-dive" id="toc-exercise-4-named-entity-deep-dive" class="nav-link" data-scroll-target="#exercise-4-named-entity-deep-dive"><span class="header-section-number">13.4</span> Exercise 4: Named entity deep dive</a></li>
  <li><a href="#exercise-5-part-of-speech-patterns-advanced" id="toc-exercise-5-part-of-speech-patterns-advanced" class="nav-link" data-scroll-target="#exercise-5-part-of-speech-patterns-advanced"><span class="header-section-number">13.5</span> Exercise 5: Part-of-speech patterns (Advanced)</a></li>
  <li><a href="#exercise-6-creating-your-own-contrasting-corpora" id="toc-exercise-6-creating-your-own-contrasting-corpora" class="nav-link" data-scroll-target="#exercise-6-creating-your-own-contrasting-corpora"><span class="header-section-number">13.6</span> Exercise 6: Creating your own contrasting corpora</a></li>
  </ul></li>
  <li><a href="#references-and-further-reading" id="toc-references-and-further-reading" class="nav-link" data-scroll-target="#references-and-further-reading"><span class="header-section-number">14</span> References and further reading</a>
  <ul>
  <li><a href="#academic-papers" id="toc-academic-papers" class="nav-link" data-scroll-target="#academic-papers"><span class="header-section-number">14.1</span> Academic papers</a></li>
  <li><a href="#textbooks" id="toc-textbooks" class="nav-link" data-scroll-target="#textbooks"><span class="header-section-number">14.2</span> Textbooks</a></li>
  <li><a href="#tutorials" id="toc-tutorials" class="nav-link" data-scroll-target="#tutorials"><span class="header-section-number">14.3</span> Tutorials</a></li>
  <li><a href="#tools" id="toc-tools" class="nav-link" data-scroll-target="#tools"><span class="header-section-number">14.4</span> Tools</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Lab 02: Words as data points II</h1>
<p class="subtitle lead">Comparing corpora, lemmatization, and statistical significance</p>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025-11-01 13:32:40</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="learning-objectives" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">1</span> Learning objectives</h2>
<p>By the end of this lab, you will understand:</p>
<ul>
<li>How to compare word usage across different groups or corpora</li>
<li>What lemmatization is and why it matters for text analysis</li>
<li>The difference between stemming and lemmatization</li>
<li>Why simple frequency comparisons can be misleading</li>
<li>How to measure statistical significance with log-likelihood (G²)</li>
<li>How to quantify effect size with log odds ratio</li>
<li>What named entities are and how to extract them</li>
<li>How to use spaCy for advanced NLP tasks in Python</li>
</ul>
<hr>
</section>
<section id="introduction-why-compare-corpora" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="introduction-why-compare-corpora"><span class="header-section-number">2</span> Introduction: Why compare corpora?</h2>
<p>In social and political science, texts often serve as proxies for social phenomena, sentiments, ideas, or discourses. A common research design involves collecting texts from different institutions, groups, or actors to create <strong>contrasting corpora</strong>. By comparing word usage across these corpora, we can infer something about the underlying social or political features of the entities they represent.</p>
<section id="the-research-question" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="the-research-question"><span class="header-section-number">2.1</span> The research question</h3>
<p>Consider this scenario: Do Democratic and Republican presidents talk differently? Not just in terms of political positions, but in the actual <em>words</em> they use?</p>
<p>In Lab 01, we compared authors based on <em>pre-selected</em> words (stop words, personal pronouns). This worked well for stylometry because function words are a closed class - we know all of them in advance.</p>
<p>But what about <strong>content words</strong>? If we want to compare the <em>substance</em> of what different groups talk about, how do we:</p>
<ol type="1">
<li>Avoid arbitrary word selection?</li>
<li>Distinguish meaningful differences from random variation?</li>
<li>Quantify both the <em>significance</em> and <em>magnitude</em> of differences?</li>
</ol>
<p>This is where corpus comparison methods come in.</p>
</section>
<section id="our-approach-today" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="our-approach-today"><span class="header-section-number">2.2</span> Our approach today</h3>
<p>We’ll create two contrasting corpora:</p>
<ul>
<li><strong>Corpus A</strong>: State of the Union addresses by Democratic presidents (since 1917)</li>
<li><strong>Corpus B</strong>: State of the Union addresses by Republican presidents (since 1917)</li>
</ul>
<p>Then we’ll use statistical measures to identify which words are significantly over- or under-used in one corpus compared to the other.</p>
<p><strong>Key insight</strong>: We’re not just looking for <em>different</em> words - we’re looking for <em>statistically significant</em> differences that reveal meaningful patterns.</p>
<hr>
</section>
</section>
<section id="setup-loading-packages" class="level2" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="setup-loading-packages"><span class="header-section-number">3</span> Setup: Loading packages</h2>
<div id="3ff078f3" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data manipulation</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Text processing</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> spacy</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistical functions</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Set visualization style</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">12</span>, <span class="dv">6</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Packages loaded successfully"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ Packages loaded successfully</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>About these packages
</div>
</div>
<div class="callout-body-container callout-body">
<p>New packages in this lab:</p>
<ul>
<li><strong>numpy</strong>: Numerical computing (for log calculations)</li>
<li><strong>scipy.stats</strong>: Statistical functions (for significance testing)</li>
</ul>
<p>We’ll continue using pandas, spaCy, and visualization libraries from Lab 01.</p>
</div>
</div>
<section id="loading-spacy-model" class="level3" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="loading-spacy-model"><span class="header-section-number">3.1</span> Loading spaCy model</h3>
<div id="fca94580" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load English language model</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nlp <span class="op">=</span> spacy.load(<span class="st">"en_core_web_sm"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>nlp.max_length <span class="op">=</span> <span class="dv">1530000</span>        <span class="co"># https://github.com/explosion/spaCy/issues/13207#issuecomment-1865973378</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"✓ spaCy model loaded: </span><span class="sc">{</span>nlp<span class="sc">.</span>meta[<span class="st">'name'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Language: </span><span class="sc">{</span>nlp<span class="sc">.</span>meta[<span class="st">'lang'</span>]<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Components: </span><span class="sc">{</span>nlp<span class="sc">.</span>pipe_names<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>✓ spaCy model loaded: core_web_sm
  Language: en
  Components: ['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="loading-and-preparing-the-data" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="loading-and-preparing-the-data"><span class="header-section-number">4</span> Loading and preparing the data</h2>
<p>Let’s load our State of the Union dataset:</p>
<div id="8a14acc4" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>speeches <span class="op">=</span> pd.read_csv(<span class="st">"data/transcripts.csv"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total speeches: </span><span class="sc">{</span><span class="bu">len</span>(speeches)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Date range: </span><span class="sc">{</span>speeches[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">min</span>()<span class="sc">}</span><span class="ss"> to </span><span class="sc">{</span>speeches[<span class="st">'date'</span>]<span class="sc">.</span><span class="bu">max</span>()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">First few rows:"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>speeches.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total speeches: 244
Date range: 1790-01-08 to 2018-01-30

First few rows:</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">date</th>
<th data-quarto-table-cell-role="th">president</th>
<th data-quarto-table-cell-role="th">title</th>
<th data-quarto-table-cell-role="th">url</th>
<th data-quarto-table-cell-role="th">transcript</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">0</th>
<td>2018-01-30</td>
<td>Donald J. Trump</td>
<td>Address Before a Joint Session of the Congress...</td>
<td>https://www.cnn.com/2018/01/30/politics/2018-s...</td>
<td>\nMr. Speaker, Mr. Vice President, Members of ...</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">1</th>
<td>2017-02-28</td>
<td>Donald J. Trump</td>
<td>Address Before a Joint Session of the Congress</td>
<td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>
<td>Thank you very much. Mr. Speaker, Mr. Vice Pre...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">2</th>
<td>2016-01-12</td>
<td>Barack Obama</td>
<td>Address Before a Joint Session of the Congress...</td>
<td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>
<td>Thank you. Mr. Speaker, Mr. Vice President, Me...</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">3</th>
<td>2015-01-20</td>
<td>Barack Obama</td>
<td>Address Before a Joint Session of the Congress...</td>
<td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>
<td>The President. Mr. Speaker, Mr. Vice President...</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">4</th>
<td>2014-01-28</td>
<td>Barack Obama</td>
<td>Address Before a Joint Session of the Congress...</td>
<td>http://www.presidency.ucsb.edu/ws/index.php?pi...</td>
<td>The President. Mr. Speaker, Mr. Vice President...</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<section id="creating-contrasting-corpora" class="level3" data-number="4.1">
<h3 data-number="4.1" class="anchored" data-anchor-id="creating-contrasting-corpora"><span class="header-section-number">4.1</span> Creating contrasting corpora</h3>
<p>We’ll split speeches by party affiliation. First, let’s define which presidents belong to which party (since 1917):</p>
<div id="0c592bcf" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Democratic presidents since 1917</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>democrats <span class="op">=</span> [</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Woodrow Wilson"</span>, </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Franklin D. Roosevelt"</span>, </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Harry S. Truman"</span>, </span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"John F. Kennedy"</span>, </span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Lyndon B. Johnson"</span>, </span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Jimmy Carter"</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"William J. Clinton"</span>, </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Barack Obama"</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter speeches</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>speeches_after_1917 <span class="op">=</span> speeches[speeches[<span class="st">'date'</span>] <span class="op">&gt;</span> <span class="st">'1917-10-25'</span>].copy()</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create party labels</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>speeches_after_1917[<span class="st">'party'</span>] <span class="op">=</span> speeches_after_1917[<span class="st">'president'</span>].<span class="bu">apply</span>(</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">lambda</span> x: <span class="st">'Democrat'</span> <span class="cf">if</span> x <span class="kw">in</span> democrats <span class="cf">else</span> <span class="st">'Republican'</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into two corpora</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>dem_speeches <span class="op">=</span> speeches_after_1917[speeches_after_1917[<span class="st">'party'</span>] <span class="op">==</span> <span class="st">'Democrat'</span>]</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>rep_speeches <span class="op">=</span> speeches_after_1917[speeches_after_1917[<span class="st">'party'</span>] <span class="op">==</span> <span class="st">'Republican'</span>]</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Democratic presidents:"</span>)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dem_speeches[<span class="st">'president'</span>].value_counts())</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total Democratic speeches: </span><span class="sc">{</span><span class="bu">len</span>(dem_speeches)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">50</span>)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Republican presidents:"</span>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(rep_speeches[<span class="st">'president'</span>].value_counts())</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total Republican speeches: </span><span class="sc">{</span><span class="bu">len</span>(rep_speeches)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Democratic presidents:
president
Franklin D. Roosevelt    13
Barack Obama              8
Harry S. Truman           8
William J. Clinton        8
Jimmy Carter              7
Lyndon B. Johnson         6
Woodrow Wilson            4
John F. Kennedy           3
Name: count, dtype: int64

Total Democratic speeches: 57

==================================================

Republican presidents:
president
Richard Nixon           12
Dwight D. Eisenhower    10
Ronald Reagan            8
George W. Bush           8
Calvin Coolidge          6
Herbert Hoover           4
George Bush              4
Gerald R. Ford           3
Donald J. Trump          2
Warren G. Harding        2
Name: count, dtype: int64

Total Republican speeches: 59</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Why start in 1917?
</div>
</div>
<div class="callout-body-container callout-body">
<p>We chose 1917 as a cutoff to:</p>
<ul>
<li>Ensure both parties have substantial representation</li>
<li>Focus on relatively modern political language</li>
<li>Avoid complications from 19th century political realignments</li>
</ul>
<p>In your own research, such choices should be <strong>explicit</strong> and <strong>justified</strong>.</p>
</div>
</div>
</section>
<section id="combining-texts-by-party" class="level3" data-number="4.2">
<h3 data-number="4.2" class="anchored" data-anchor-id="combining-texts-by-party"><span class="header-section-number">4.2</span> Combining texts by party</h3>
<p>For corpus comparison, we’ll combine all speeches from each party into two large text collections:</p>
<div id="f72f1b02" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine all speeches by party</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>dem_corpus <span class="op">=</span> <span class="st">" "</span>.join(dem_speeches[<span class="st">'transcript'</span>].tolist())</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>rep_corpus <span class="op">=</span> <span class="st">" "</span>.join(rep_speeches[<span class="st">'transcript'</span>].tolist())</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Democratic corpus: </span><span class="sc">{</span><span class="bu">len</span>(dem_corpus)<span class="sc">:,}</span><span class="ss"> characters"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Republican corpus: </span><span class="sc">{</span><span class="bu">len</span>(rep_corpus)<span class="sc">:,}</span><span class="ss"> characters"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Democratic corpus: 4,874,617 characters
Republican corpus: 4,176,938 characters</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="from-wordforms-to-lemmas-introduction-to-lemmatization" class="level2" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="from-wordforms-to-lemmas-introduction-to-lemmatization"><span class="header-section-number">5</span> From wordforms to lemmas: Introduction to lemmatization</h2>
<section id="the-problem-with-raw-words" class="level3" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="the-problem-with-raw-words"><span class="header-section-number">5.1</span> The problem with raw words</h3>
<p>Consider these sentences:</p>
<ul>
<li>“The government <strong>regulates</strong> industry.”</li>
<li>“These <strong>regulations</strong> affect small businesses.”</li>
<li>“The <strong>regulatory</strong> framework is complex.”</li>
</ul>
<p>These three words - <em>regulates</em>, <em>regulations</em>, <em>regulatory</em> - are clearly related. They share the same root concept of “regulation.” But if we count them separately, we miss this connection.</p>
<p>This problem is especially acute in languages with rich inflection (Russian, German, Finnish), but it exists in English too:</p>
<ul>
<li>Verbs: walk, walks, walked, walking</li>
<li>Nouns: cat, cats, mouse, mice</li>
<li>Adjectives: big, bigger, biggest</li>
</ul>
</section>
<section id="two-solutions-stemming-vs-lemmatization" class="level3" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="two-solutions-stemming-vs-lemmatization"><span class="header-section-number">5.2</span> Two solutions: Stemming vs lemmatization</h3>
<p><strong>Stemming</strong>: Crudely chop off word endings</p>
<ul>
<li>running → run</li>
<li>better → bet (⚠️ wrong!)</li>
<li>organization → organ (⚠️ wrong!)</li>
<li>Fast but imprecise</li>
</ul>
<p><strong>Lemmatization</strong>: Reduce words to their dictionary form (<em>lemma</em>)</p>
<ul>
<li>running → run</li>
<li>better → good</li>
<li>mice → mouse</li>
<li>Slower but accurate</li>
</ul>
</section>
<section id="how-lemmatization-works" class="level3" data-number="5.3">
<h3 data-number="5.3" class="anchored" data-anchor-id="how-lemmatization-works"><span class="header-section-number">5.3</span> How lemmatization works</h3>
<p>Lemmatization requires:</p>
<ol type="1">
<li><strong>Part-of-speech information</strong>: Is “running” a verb or a noun?</li>
<li><strong>Morphological dictionary</strong>: What are all the forms of “run”?</li>
<li><strong>Linguistic rules</strong>: How do irregular forms work?</li>
</ol>
<p>Fortunately, spaCy does all this for us!</p>
</section>
<section id="lemmatization-with-spacy" class="level3" data-number="5.4">
<h3 data-number="5.4" class="anchored" data-anchor-id="lemmatization-with-spacy"><span class="header-section-number">5.4</span> Lemmatization with spaCy</h3>
<p>Let’s see lemmatization in action:</p>
<div id="316445ac" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example text</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>example <span class="op">=</span> <span class="st">"The regulations are regulating industries more effectively than previous regulatory frameworks."</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Process with spaCy</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>doc <span class="op">=</span> nlp(example)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Show original word, lemma, and part of speech</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Word → Lemma (Part of Speech)"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">40</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> doc:</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> token.is_punct:</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>token<span class="sc">.</span>text<span class="sc">:15}</span><span class="ss"> → </span><span class="sc">{</span>token<span class="sc">.</span>lemma_<span class="sc">:15}</span><span class="ss"> (</span><span class="sc">{</span>token<span class="sc">.</span>pos_<span class="sc">}</span><span class="ss">)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Word → Lemma (Part of Speech)
----------------------------------------
The             → the             (DET)
regulations     → regulation      (NOUN)
are             → be              (AUX)
regulating      → regulate        (VERB)
industries      → industry        (NOUN)
more            → more            (ADV)
effectively     → effectively     (ADV)
than            → than            (ADP)
previous        → previous        (ADJ)
regulatory      → regulatory      (ADJ)
frameworks      → framework       (NOUN)</code></pre>
</div>
</div>
<p>Notice how:</p>
<ul>
<li>“regulations” → “regulation”</li>
<li>“are regulating” → “be regulate” (splits auxiliary verb)</li>
<li>“regulatory” → “regulatory” (already base form)</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>When to lemmatize?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Use lemmatization when:</strong></p>
<ul>
<li>Comparing content across documents</li>
<li>Building topic models</li>
<li>Working with inflected languages</li>
<li>Vocabulary is too large</li>
</ul>
<p><strong>Don’t lemmatize when:</strong></p>
<ul>
<li>Doing stylometry (exact forms matter)</li>
<li>Studying syntax or grammar</li>
<li>Tense/number/person is important</li>
<li>Training neural language models</li>
</ul>
</div>
</div>
<hr>
</section>
</section>
<section id="processing-our-corpora-with-spacy" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="processing-our-corpora-with-spacy"><span class="header-section-number">6</span> Processing our corpora with spaCy</h2>
<p>Now let’s lemmatize both of our political corpora. This will take a few minutes as spaCy processes all the text.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Processing time
</div>
</div>
<div class="callout-body-container callout-body">
<p>Processing large texts with spaCy is computationally intensive. For very large corpora (millions of words), you might want to:</p>
<ul>
<li>Use spaCy’s <code>nlp.pipe()</code> for batch processing</li>
<li>Disable unnecessary components (<code>nlp.disable_pipes()</code>)</li>
<li>Save processed results to disk</li>
</ul>
<p>For this lab, the processing should take 2-5 minutes.</p>
</div>
</div>
<div id="9e23d9f6" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Process Democratic speeches (this takes time!)</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Processing Democratic speeches..."</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>dem_doc <span class="op">=</span> nlp(dem_corpus)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Democratic corpus processed"</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Process Republican speeches</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Processing Republican speeches..."</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>rep_doc <span class="op">=</span> nlp(rep_corpus)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Republican corpus processed"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>For the purposes of this lab, let’s work with a sample to speed things up:</p>
<div id="3444533f" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a sample of each corpus for faster processing</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>dem_sample <span class="op">=</span> <span class="st">" "</span>.join(dem_speeches.sample(n<span class="op">=</span><span class="bu">min</span>(<span class="dv">20</span>, <span class="bu">len</span>(dem_speeches)), random_state<span class="op">=</span><span class="dv">42</span>)[<span class="st">'transcript'</span>].tolist())</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>rep_sample <span class="op">=</span> <span class="st">" "</span>.join(rep_speeches.sample(n<span class="op">=</span><span class="bu">min</span>(<span class="dv">20</span>, <span class="bu">len</span>(rep_speeches)), random_state<span class="op">=</span><span class="dv">42</span>)[<span class="st">'transcript'</span>].tolist())</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Process samples</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Processing samples..."</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>dem_doc <span class="op">=</span> nlp(dem_sample)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>rep_doc <span class="op">=</span> nlp(rep_sample)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"✓ Processing complete"</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Democratic sample: </span><span class="sc">{</span><span class="bu">len</span>(dem_doc)<span class="sc">}</span><span class="ss"> tokens"</span>)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Republican sample: </span><span class="sc">{</span><span class="bu">len</span>(rep_doc)<span class="sc">}</span><span class="ss"> tokens"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Processing samples...
✓ Processing complete

Democratic sample: 295013 tokens
Republican sample: 267382 tokens</code></pre>
</div>
</div>
<section id="extracting-lemmas-and-filtering" class="level3" data-number="6.1">
<h3 data-number="6.1" class="anchored" data-anchor-id="extracting-lemmas-and-filtering"><span class="header-section-number">6.1</span> Extracting lemmas and filtering</h3>
<p>We want to keep only content-bearing words. Let’s filter out:</p>
<ul>
<li>Punctuation (<code>.</code>, <code>,</code>, <code>!</code>, etc.)</li>
<li>Numbers (<code>1</code>, <code>2020</code>, <code>million</code>)</li>
<li>Symbols (<code>$</code>, <code>%</code>, <code>@</code>)</li>
<li>Proper nouns (specific names of people and places)</li>
<li>Stop words (optional - let’s keep them for now to see what happens)</li>
</ul>
<div id="4e52f7e7" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract lemmas from Democratic speeches</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>dem_lemmas <span class="op">=</span> []</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> dem_doc:</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> token.is_punct <span class="kw">and</span> <span class="kw">not</span> token.is_space <span class="kw">and</span> token.pos_ <span class="kw">not</span> <span class="kw">in</span> [<span class="st">'NUM'</span>, <span class="st">'SYM'</span>, <span class="st">'PROPN'</span>]:</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        dem_lemmas.append({</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">'lemma'</span>: token.lemma_.lower(),</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">'pos'</span>: token.pos_,</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">'party'</span>: <span class="st">'Democrat'</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract lemmas from Republican speeches</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>rep_lemmas <span class="op">=</span> []</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> token <span class="kw">in</span> rep_doc:</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> token.is_punct <span class="kw">and</span> <span class="kw">not</span> token.is_space <span class="kw">and</span> token.pos_ <span class="kw">not</span> <span class="kw">in</span> [<span class="st">'NUM'</span>, <span class="st">'SYM'</span>, <span class="st">'PROPN'</span>]:</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>        rep_lemmas.append({</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>            <span class="st">'lemma'</span>: token.lemma_.lower(),</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>            <span class="st">'pos'</span>: token.pos_,</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>            <span class="st">'party'</span>: <span class="st">'Republican'</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>        })</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine into DataFrames</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>dem_df <span class="op">=</span> pd.DataFrame(dem_lemmas)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>rep_df <span class="op">=</span> pd.DataFrame(rep_lemmas)</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Democratic lemmas: </span><span class="sc">{</span><span class="bu">len</span>(dem_df)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Republican lemmas: </span><span class="sc">{</span><span class="bu">len</span>(rep_df)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Sample of Democratic lemmas:"</span>)</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(dem_df.head(<span class="dv">10</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Democratic lemmas: 247,919
Republican lemmas: 225,161

Sample of Democratic lemmas:
     lemma   pos     party
0    thank  VERB  Democrat
1      you  PRON  Democrat
2       of   ADP  Democrat
3       my  PRON  Democrat
4   fellow   ADJ  Democrat
5  tonight  NOUN  Democrat
6     mark  VERB  Democrat
7      the   DET  Democrat
8   eighth   ADJ  Democrat
9     year  NOUN  Democrat</code></pre>
</div>
</div>
</section>
<section id="creating-frequency-tables" class="level3" data-number="6.2">
<h3 data-number="6.2" class="anchored" data-anchor-id="creating-frequency-tables"><span class="header-section-number">6.2</span> Creating frequency tables</h3>
<p>Now let’s count how often each lemma appears in each corpus:</p>
<div id="e12df5c1" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Count frequencies by party</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>dem_counts <span class="op">=</span> dem_df[<span class="st">'lemma'</span>].value_counts().reset_index()</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>dem_counts.columns <span class="op">=</span> [<span class="st">'lemma'</span>, <span class="st">'democrat'</span>]</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>rep_counts <span class="op">=</span> rep_df[<span class="st">'lemma'</span>].value_counts().reset_index()</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>rep_counts.columns <span class="op">=</span> [<span class="st">'lemma'</span>, <span class="st">'republican'</span>]</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge into one table</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>freq_table <span class="op">=</span> dem_counts.merge(rep_counts, on<span class="op">=</span><span class="st">'lemma'</span>, how<span class="op">=</span><span class="st">'outer'</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to integers</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>freq_table[<span class="st">'democrat'</span>] <span class="op">=</span> freq_table[<span class="st">'democrat'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>freq_table[<span class="st">'republican'</span>] <span class="op">=</span> freq_table[<span class="st">'republican'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter out very rare words (appears less than 10 times in both corpora)</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>freq_table <span class="op">=</span> freq_table[(freq_table[<span class="st">'democrat'</span>] <span class="op">&gt;</span> <span class="dv">10</span>) <span class="op">|</span> (freq_table[<span class="st">'republican'</span>] <span class="op">&gt;</span> <span class="dv">10</span>)].copy()</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Unique lemmas (after filtering): </span><span class="sc">{</span><span class="bu">len</span>(freq_table)<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Top 20 by total frequency:"</span>)</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>freq_table[<span class="st">'total'</span>] <span class="op">=</span> freq_table[<span class="st">'democrat'</span>] <span class="op">+</span> freq_table[<span class="st">'republican'</span>]</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(freq_table.sort_values(<span class="st">'total'</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">20</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Unique lemmas (after filtering): 2,072

Top 20 by total frequency:
     lemma  democrat  republican  total
6817   the     14722       14995  29717
4617    of      8965        9654  18619
395    and      9610        8446  18056
6915    to      9536        7944  17480
708     be      8286        8421  16707
3462    in      5361        5390  10751
7507    we      5757        4214   9971
94       a      4410        4106   8516
4700   our      4423        3595   8018
6816  that      3850        2843   6693
3187  have      3386        3183   6569
2805   for      2936        2765   5701
3364     i      2742        1921   4663
7583  will      2390        1964   4354
3797    it      1995        1740   3735
6849  this      1952        1738   3690
4548   not      1780        1372   3152
7604  with      1626        1383   3009
4640    on      1419        1445   2864
6842  they      1658        1065   2723</code></pre>
</div>
</div>
<hr>
</section>
</section>
<section id="the-problem-with-simple-frequency-comparisons" class="level2" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="the-problem-with-simple-frequency-comparisons"><span class="header-section-number">7</span> The problem with simple frequency comparisons</h2>
<p>Looking at raw frequencies is tempting, but it can be misleading. Let’s see why.</p>
<section id="corpus-size-matters" class="level3" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="corpus-size-matters"><span class="header-section-number">7.1</span> Corpus size matters</h3>
<div id="461c72fe" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Total tokens per party</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>total_dem <span class="op">=</span> freq_table[<span class="st">'democrat'</span>].<span class="bu">sum</span>()</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>total_rep <span class="op">=</span> freq_table[<span class="st">'republican'</span>].<span class="bu">sum</span>()</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total Democratic tokens: </span><span class="sc">{</span>total_dem<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total Republican tokens: </span><span class="sc">{</span>total_rep<span class="sc">:,}</span><span class="ss">"</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Ratio (Dem/Rep): </span><span class="sc">{</span>total_dem<span class="op">/</span>total_rep<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Total Democratic tokens: 234,922
Total Republican tokens: 212,286
Ratio (Dem/Rep): 1.11</code></pre>
</div>
</div>
<p>If one corpus is larger, it will naturally have higher raw counts for most words. We need to account for this.</p>
</section>
<section id="example-the-word-people" class="level3" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="example-the-word-people"><span class="header-section-number">7.2</span> Example: The word “people”</h3>
<div id="402d1c1e" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Look at a specific word</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>people_row <span class="op">=</span> freq_table[freq_table[<span class="st">'lemma'</span>] <span class="op">==</span> <span class="st">'people'</span>]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(people_row) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    dem_count <span class="op">=</span> people_row[<span class="st">'democrat'</span>].values[<span class="dv">0</span>]</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    rep_count <span class="op">=</span> people_row[<span class="st">'republican'</span>].values[<span class="dv">0</span>]</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Raw counts</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Raw counts for 'people':"</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Democrats: </span><span class="sc">{</span>dem_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Republicans: </span><span class="sc">{</span>rep_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Difference: </span><span class="sc">{</span>dem_count <span class="op">-</span> rep_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalized (per 1000 words)</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>    dem_rate <span class="op">=</span> (dem_count <span class="op">/</span> total_dem) <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    rep_rate <span class="op">=</span> (rep_count <span class="op">/</span> total_rep) <span class="op">*</span> <span class="dv">1000</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Normalized rates (per 1,000 words):"</span>)</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Democrats: </span><span class="sc">{</span>dem_rate<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Republicans: </span><span class="sc">{</span>rep_rate<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Difference: </span><span class="sc">{</span>dem_rate <span class="op">-</span> rep_rate<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Raw counts for 'people':
  Democrats: 972
  Republicans: 687
  Difference: 285

Normalized rates (per 1,000 words):
  Democrats: 4.14
  Republicans: 3.24
  Difference: 0.90</code></pre>
</div>
</div>
<p>The raw difference might be large just because one corpus is bigger!</p>
</section>
<section id="two-questions-we-need-to-answer" class="level3" data-number="7.3">
<h3 data-number="7.3" class="anchored" data-anchor-id="two-questions-we-need-to-answer"><span class="header-section-number">7.3</span> Two questions we need to answer</h3>
<ol type="1">
<li><strong>Is the difference statistically significant?</strong>
<ul>
<li>Could this difference occur by chance?</li>
<li>How confident can we be that it’s a real pattern?</li>
<li>→ We’ll use <strong>log-likelihood (G²)</strong> for this</li>
</ul></li>
<li><strong>How large is the effect?</strong>
<ul>
<li>Is it a huge difference or a tiny one?</li>
<li>Which words show the strongest contrast?</li>
<li>→ We’ll use <strong>log odds ratio</strong> for this</li>
</ul></li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Statistical significance ≠ practical importance
</div>
</div>
<div class="callout-body-container callout-body">
<p>A difference can be:</p>
<ul>
<li><strong>Statistically significant</strong> but <strong>tiny</strong> (large sample)</li>
<li><strong>Large</strong> but <strong>not significant</strong> (small sample)</li>
</ul>
<p>We need <em>both</em> measures to draw meaningful conclusions.</p>
</div>
</div>
<hr>
</section>
</section>
<section id="measuring-significance-log-likelihood-g²" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="measuring-significance-log-likelihood-g²"><span class="header-section-number">8</span> Measuring significance: Log-likelihood (G²)</h2>
<section id="the-problem-when-is-a-difference-real" class="level3" data-number="8.1">
<h3 data-number="8.1" class="anchored" data-anchor-id="the-problem-when-is-a-difference-real"><span class="header-section-number">8.1</span> The problem: When is a difference real?</h3>
<p>Let’s say we’re comparing Republican and Democratic speeches, and we find that the word “freedom” appears:</p>
<ul>
<li>100 times in Republican speeches</li>
<li>50 times in Democratic speeches</li>
</ul>
<p>Should we conclude that Republicans talk twice as much about freedom?</p>
<p>Not necessarily. Here’s why: What if the Republican corpus contains 1,000,000 words total, while the Democratic corpus contains 500,000 words? Then both parties use “freedom” at exactly the same rate (100 per million words). The difference in raw counts is simply because we have more Republican text.</p>
<p>This is why we need a statistical test that accounts for corpus size.</p>
</section>
<section id="what-is-log-likelihood-g²" class="level3" data-number="8.2">
<h3 data-number="8.2" class="anchored" data-anchor-id="what-is-log-likelihood-g²"><span class="header-section-number">8.2</span> What is log-likelihood (G²)?</h3>
<p>Log-likelihood, abbreviated as <strong>G²</strong>, is a statistical test that answers one simple question:</p>
<blockquote class="blockquote">
<p><em>“Given the sizes of my two corpora, how surprising is this word’s distribution?”</em></p>
</blockquote>
<p><strong>The logic:</strong></p>
<ul>
<li>If a word is distributed just as we’d expect (proportional to corpus size), G² is close to 0</li>
<li>If the distribution is very different from what we’d expect, G² is large</li>
<li>The larger G², the more confident we can be that the difference is real, not just random variation</li>
</ul>
<p>Think of G² as a “surprise meter” - it measures how surprised we should be by what we observe.</p>
</section>
<section id="how-to-read-g²-values" class="level3" data-number="8.3">
<h3 data-number="8.3" class="anchored" data-anchor-id="how-to-read-g²-values"><span class="header-section-number">8.3</span> How to read G² values</h3>
<p>G² follows a well-known statistical distribution, which means we have standard thresholds for interpretation:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 41%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th>G² value</th>
<th>Confidence level</th>
<th>What it means</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>&lt; 3.84</td>
<td>Not significant</td>
<td>Difference might be random chance</td>
</tr>
<tr class="even">
<td>&gt; 3.84</td>
<td>95% confident</td>
<td>Probably a real pattern (p &lt; 0.05)</td>
</tr>
<tr class="odd">
<td>&gt; 6.63</td>
<td>99% confident</td>
<td>Very likely a real pattern (p &lt; 0.01)</td>
</tr>
<tr class="even">
<td>&gt; 10.83</td>
<td>99.9% confident</td>
<td>Almost certainly a real pattern (p &lt; 0.001)</td>
</tr>
</tbody>
</table>
<p><strong>Rule of thumb</strong>: We typically use <strong>G² &gt; 6.63</strong> as our cutoff for trusting a difference.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>What does “99% confident” mean?
</div>
</div>
<div class="callout-body-container callout-body">
<p>It means: “If there were actually no real difference, we’d see a result this extreme less than 1% of the time.” In other words, we’re very confident the pattern is real, not just luck.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>For the mathematically curious: How G² is calculated
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>G² compares observed frequencies (what we actually see) to expected frequencies (what we’d see if words were distributed proportionally to corpus size).</p>
<p>The formula is:</p>
<p><span class="math display">\[G^2 = 2 \sum O \times \ln\left(\frac{O}{E}\right)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(O\)</span> = observed frequency</li>
<li><span class="math inline">\(E\)</span> = expected frequency</li>
<li><span class="math inline">\(\ln\)</span> = natural logarithm</li>
</ul>
<p>For two corpora, this expands to:</p>
<p><span class="math display">\[G^2 = 2 \times \left[ a \times \ln\left(\frac{a}{E_1}\right) + b \times \ln\left(\frac{b}{E_2}\right) \right]\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(a\)</span> = word count in Corpus A</li>
<li><span class="math inline">\(b\)</span> = word count in Corpus B</li>
<li><span class="math inline">\(E_1\)</span> = expected count in Corpus A</li>
<li><span class="math inline">\(E_2\)</span> = expected count in Corpus B</li>
</ul>
<p>The expected frequencies account for corpus size:</p>
<p><span class="math display">\[E_1 = C \times \frac{a + b}{C + D}\]</span> <span class="math display">\[E_2 = D \times \frac{a + b}{C + D}\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(C\)</span> = total size of Corpus A</li>
<li><span class="math inline">\(D\)</span> = total size of Corpus B</li>
</ul>
<p>This test is based on Dunning (1993), a foundational paper in corpus linguistics. It’s preferred over chi-squared for text data because it handles sparse data (rare words) more reliably.</p>
</div>
</div>
</div>
</section>
<section id="calculating-g²-in-python" class="level3" data-number="8.4">
<h3 data-number="8.4" class="anchored" data-anchor-id="calculating-g²-in-python"><span class="header-section-number">8.4</span> Calculating G² in Python</h3>
<p>We’ll create a function that does all the mathematical work for us:</p>
<div id="3bb88793" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_likelihood(a, b):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculate log-likelihood (G²) for word frequencies in two corpora.</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function compares observed word frequencies to expected frequencies</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co">    (based on corpus size) and returns a G² value indicating how surprising</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co">    the observed distribution is.</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">    a : array-like</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">        Word counts in corpus A (e.g., Democratic speeches)</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">    b : array-like</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co">        Word counts in corpus B (e.g., Republican speeches)</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a><span class="co">    array-like</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="co">        G² values for each word (higher = more surprising/significant)</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Total corpus sizes</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> np.<span class="bu">sum</span>(a)  <span class="co"># Total tokens in corpus A</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> np.<span class="bu">sum</span>(b)  <span class="co"># Total tokens in corpus B</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate expected frequencies (what we'd expect if words were distributed proportionally)</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>    E1 <span class="op">=</span> C <span class="op">*</span> ((a <span class="op">+</span> b) <span class="op">/</span> (C <span class="op">+</span> D))</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>    E2 <span class="op">=</span> D <span class="op">*</span> ((a <span class="op">+</span> b) <span class="op">/</span> (C <span class="op">+</span> D))</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate G² statistic</span></span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Note: We add a tiny constant (1e-10) to avoid mathematical errors when counts are zero</span></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>    g2 <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> ((a <span class="op">*</span> np.log(a <span class="op">/</span> E1 <span class="op">+</span> <span class="fl">1e-10</span>)) <span class="op">+</span> (b <span class="op">*</span> np.log(b <span class="op">/</span> E2 <span class="op">+</span> <span class="fl">1e-10</span>)))</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> g2</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="using-g²-to-find-significant-differences" class="level3" data-number="8.5">
<h3 data-number="8.5" class="anchored" data-anchor-id="using-g²-to-find-significant-differences"><span class="header-section-number">8.5</span> Using G² to find significant differences</h3>
<div id="315db282" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate log-likelihood for all words</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>freq_table[<span class="st">'g2'</span>] <span class="op">=</span> log_likelihood(</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    freq_table[<span class="st">'democrat'</span>].values, </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    freq_table[<span class="st">'republican'</span>].values</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by G² (most significant differences)</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>freq_table_sorted <span class="op">=</span> freq_table.sort_values(<span class="st">'g2'</span>, ascending<span class="op">=</span><span class="va">False</span>).copy()</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Words with highest G² (most significant differences):"</span>)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(freq_table_sorted[[<span class="st">'lemma'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'g2'</span>]].head(<span class="dv">20</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Words with highest G² (most significant differences):
            lemma  democrat  republican          g2
2095           do      1380         612  231.203248
2986          get       421         122  145.273635
4617           of      8965        9654  143.074502
7675          you       941         443  136.369324
7625         work      1034         505  135.944566
7507           we      5757        4214  108.982754
5829        right       503         198  108.139684
6817          the     14722       14995  106.400966
7343           us       174          28  103.171606
1226      college       174          29  100.740012
3123          gun        78           0  100.428162
3813          job       544         232   99.441736
1061         cent         6          86   91.520368
5163      present        86         238   90.417812
7555        which       805        1117   87.414119
7560          who       837         443   86.633621
1278      company       120          14   85.637924
4673           or       930         514   83.115776
2546  expenditure        28         130   82.156755
6803    terrorist        42         156   81.910170</code></pre>
</div>
</div>
<p>Look at the G² values. Many are well above 6.63, meaning we can be very confident these differences are real.</p>
</section>
<section id="how-many-significant-differences-did-we-find" class="level3" data-number="8.6">
<h3 data-number="8.6" class="anchored" data-anchor-id="how-many-significant-differences-did-we-find"><span class="header-section-number">8.6</span> How many significant differences did we find?</h3>
<p>Let’s count how many words show statistically significant differences at different confidence levels:</p>
<div id="fa7867f2" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Count significant differences</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>sig_05 <span class="op">=</span> (freq_table[<span class="st">'g2'</span>] <span class="op">&gt;</span> <span class="fl">3.84</span>).<span class="bu">sum</span>()</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>sig_01 <span class="op">=</span> (freq_table[<span class="st">'g2'</span>] <span class="op">&gt;</span> <span class="fl">6.63</span>).<span class="bu">sum</span>()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>sig_001 <span class="op">=</span> (freq_table[<span class="st">'g2'</span>] <span class="op">&gt;</span> <span class="fl">10.83</span>).<span class="bu">sum</span>()</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Significant differences:"</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  95% confident (G² &gt; 3.84):   </span><span class="sc">{</span>sig_05<span class="sc">}</span><span class="ss"> words"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  99% confident (G² &gt; 6.63):   </span><span class="sc">{</span>sig_01<span class="sc">}</span><span class="ss"> words"</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  99.9% confident (G² &gt; 10.83): </span><span class="sc">{</span>sig_001<span class="sc">}</span><span class="ss"> words"</span>)</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total words tested: </span><span class="sc">{</span><span class="bu">len</span>(freq_table)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Significant differences:
  95% confident (G² &gt; 3.84):   994 words
  99% confident (G² &gt; 6.63):   737 words
  99.9% confident (G² &gt; 10.83): 487 words

Total words tested: 2072</code></pre>
</div>
</div>
<p>So we have hundreds of words with statistically significant differences. But are they all interesting?</p>
</section>
<section id="the-problem-stop-words-dominate" class="level3" data-number="8.7">
<h3 data-number="8.7" class="anchored" data-anchor-id="the-problem-stop-words-dominate"><span class="header-section-number">8.7</span> The problem: Stop words dominate</h3>
<p>Not all statistically significant differences are interesting. Let’s check what kinds of words have the highest G² values:</p>
<div id="fbeb684f" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load stop words from spaCy</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> nlp.Defaults.stop_words</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check if top G² words are stop words</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>freq_table_sorted[<span class="st">'is_stopword'</span>] <span class="op">=</span> freq_table_sorted[<span class="st">'lemma'</span>].isin(stop_words)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 20 by G² - are they stop words?"</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(freq_table_sorted[[<span class="st">'lemma'</span>, <span class="st">'g2'</span>, <span class="st">'is_stopword'</span>]].head(<span class="dv">20</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 20 by G² - are they stop words?
            lemma          g2  is_stopword
2095           do  231.203248         True
2986          get  145.273635         True
4617           of  143.074502         True
7675          you  136.369324         True
7625         work  135.944566        False
7507           we  108.982754         True
5829        right  108.139684        False
6817          the  106.400966         True
7343           us  103.171606         True
1226      college  100.740012        False
3123          gun  100.428162        False
3813          job   99.441736        False
1061         cent   91.520368        False
5163      present   90.417812        False
7555        which   87.414119         True
7560          who   86.633621         True
1278      company   85.637924        False
4673           or   83.115776         True
2546  expenditure   82.156755        False
6803    terrorist   81.910170        False</code></pre>
</div>
</div>
<p>Notice that many high-G² words are stop words (words like “the”, “and”, “of”).</p>
<p><strong>Why does this happen?</strong></p>
<ul>
<li>Stop words appear thousands of times in our corpora</li>
<li>G² is sensitive to absolute frequencies - when a word appears 5,000 times, even a small proportional difference produces high G²</li>
<li>A word that’s 51% vs 49% between corpora can have higher G² than a word that’s 90% vs 10%, just because the first word is more common overall</li>
</ul>
<p><strong>The solution</strong>: Filter to focus on content words (nouns, verbs, adjectives) by removing stop words.</p>
<div id="e27d99b3" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Focus on content words by removing stop words</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>content_words <span class="op">=</span> freq_table_sorted[<span class="op">~</span>freq_table_sorted[<span class="st">'is_stopword'</span>]].copy()</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Top 20 content words by G²:"</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(content_words[[<span class="st">'lemma'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'g2'</span>]].head(<span class="dv">20</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Top 20 content words by G²:
            lemma  democrat  republican          g2
7625         work      1034         505  135.944566
5829        right       503         198  108.139684
1226      college       174          29  100.740012
3123          gun        78           0  100.428162
3813          job       544         232   99.441736
1061         cent         6          86   91.520368
5163      present        86         238   90.417812
1278      company       120          14   85.637924
2546  expenditure        28         130   82.156755
6803    terrorist        42         156   81.910170
7477         want       326         119   80.271861
3164         hard       196          51   76.786385
1582        court        18         103   74.890387
3866         know       423         186   72.262874
5282     property         6          67   66.090068
776           big       120          25   58.448358
6891         tile         0          38   56.626794
5806      revenue        22          94   55.715059
4211      measure        66         166   55.275584
1830    dependent         2          46   54.495605</code></pre>
</div>
</div>
<p>Much better! Now we’re seeing substantive words about policy, governance, and political issues.</p>
</section>
<section id="what-g²-doesnt-tell-us" class="level3" data-number="8.8">
<h3 data-number="8.8" class="anchored" data-anchor-id="what-g²-doesnt-tell-us"><span class="header-section-number">8.8</span> What G² doesn’t tell us</h3>
<p>G² tells us <strong>that</strong> a difference exists and how confident we can be about it. But it doesn’t tell us:</p>
<ol type="1">
<li><strong>Which corpus</strong> uses the word more</li>
<li><strong>How much more</strong> it’s used</li>
</ol>
<p>For that, we need another measure: log odds ratio.</p>
<hr>
</section>
</section>
<section id="measuring-effect-size-log-odds-ratio" class="level2" data-number="9">
<h2 data-number="9" class="anchored" data-anchor-id="measuring-effect-size-log-odds-ratio"><span class="header-section-number">9</span> Measuring effect size: Log odds ratio</h2>
<section id="the-problem-g²-doesnt-tell-us-everything" class="level3" data-number="9.1">
<h3 data-number="9.1" class="anchored" data-anchor-id="the-problem-g²-doesnt-tell-us-everything"><span class="header-section-number">9.1</span> The problem: G² doesn’t tell us everything</h3>
<p>Look back at the content words with high G² values. Can you quickly tell which party uses each word more? Is “health” more Democratic or Republican? What about “security”?</p>
<p>G² told us that differences exist and that they’re statistically significant. But it doesn’t tell us:</p>
<ol type="1">
<li><strong>Direction</strong>: Which corpus uses the word more?</li>
<li><strong>Magnitude</strong>: Is it slightly more common, or dramatically more common?</li>
</ol>
<p>For this, we need a different measure: <strong>log odds ratio</strong>.</p>
</section>
<section id="what-is-log-odds-ratio" class="level3" data-number="9.2">
<h3 data-number="9.2" class="anchored" data-anchor-id="what-is-log-odds-ratio"><span class="header-section-number">9.2</span> What is log odds ratio?</h3>
<p>Log odds ratio is a measure of <strong>effect size</strong> that answers:</p>
<blockquote class="blockquote">
<p><em>“How much more is this word used in one corpus compared to the other?”</em></p>
</blockquote>
<p>It gives us two pieces of information:</p>
<ul>
<li><strong>The sign</strong> (+ or -) tells us which corpus uses the word more</li>
<li><strong>The number</strong> tells us how much more it’s used</li>
</ul>
</section>
<section id="how-to-read-log-odds-values" class="level3" data-number="9.3">
<h3 data-number="9.3" class="anchored" data-anchor-id="how-to-read-log-odds-values"><span class="header-section-number">9.3</span> How to read log odds values</h3>
<p>In our analysis, we calculate log odds where:</p>
<ul>
<li><strong>Positive values</strong> = word is more common in Democratic speeches</li>
<li><strong>Negative values</strong> = word is more common in Republican speeches</li>
<li><strong>Zero</strong> = word is equally common in both</li>
</ul>
<p>The magnitude tells us how big the difference is:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Log Odds</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>+1.0</td>
<td>Word is 2× more common in Democratic speeches</td>
</tr>
<tr class="even">
<td>+2.0</td>
<td>Word is 4× more common in Democratic speeches</td>
</tr>
<tr class="odd">
<td>+3.0</td>
<td>Word is 8× more common in Democratic speeches</td>
</tr>
<tr class="even">
<td>-1.0</td>
<td>Word is 2× more common in Republican speeches</td>
</tr>
<tr class="odd">
<td>-2.0</td>
<td>Word is 4× more common in Republican speeches</td>
</tr>
<tr class="even">
<td>0.0</td>
<td>Word is equally common in both</td>
</tr>
</tbody>
</table>
</section>
<section id="a-concrete-example" class="level3" data-number="9.4">
<h3 data-number="9.4" class="anchored" data-anchor-id="a-concrete-example"><span class="header-section-number">9.4</span> A concrete example</h3>
<p>Let’s say the word “healthcare” appears:</p>
<ul>
<li>200 times in Democratic speeches (out of 100,000 total Democratic words)</li>
<li>50 times in Republican speeches (out of 100,000 total Republican words)</li>
</ul>
<p>The proportions are:</p>
<ul>
<li>Democratic: 200/100,000 = 0.002 (0.2%)</li>
<li>Republican: 50/100,000 = 0.0005 (0.05%)</li>
</ul>
<p>The ratio is 0.002/0.0005 = 4.0 (Democrats use it 4× more often).</p>
<p>The log₂(4.0) = 2.0</p>
<p>So this word would have a <strong>log odds ratio of +2.0</strong>, meaning Democrats use it 4× more than Republicans.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Why use logarithm?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Raw ratios are asymmetric and hard to interpret:</p>
<ul>
<li>“2× more common” = ratio of 2.0</li>
<li>“2× less common” = ratio of 0.5</li>
</ul>
<p>These don’t look symmetric even though they represent the same magnitude of difference.</p>
<p>Taking the logarithm makes them symmetric:</p>
<ul>
<li>2× more common: log₂(2.0) = +1.0</li>
<li>2× less common: log₂(0.5) = -1.0</li>
</ul>
<p>We use <strong>base-2 logarithm</strong> (log₂) because it’s easy to interpret:</p>
<ul>
<li>Each +1 means “doubled”</li>
<li>Each -1 means “halved”</li>
</ul>
<p>This makes effect sizes comparable across different words.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>The mathematical formula
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Log odds ratio is calculated as:</p>
<p><span class="math display">\[\text{Log Odds Ratio} = \log_2\left(\frac{a/C}{b/D}\right)\]</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\(a\)</span> = word count in Corpus A (Democrats)</li>
<li><span class="math inline">\(b\)</span> = word count in Corpus B (Republicans)</li>
<li><span class="math inline">\(C\)</span> = total size of Corpus A</li>
<li><span class="math inline">\(D\)</span> = total size of Corpus B</li>
</ul>
<p>This simplifies to comparing the proportions (a/C vs b/D) of how often each corpus uses the word.</p>
</div>
</div>
</div>
</section>
<section id="calculating-log-odds-ratio-in-python" class="level3" data-number="9.5">
<h3 data-number="9.5" class="anchored" data-anchor-id="calculating-log-odds-ratio-in-python"><span class="header-section-number">9.5</span> Calculating log odds ratio in Python</h3>
<p>Let’s create a function to calculate log odds ratio for all our words:</p>
<div id="0508dfe4" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_odds_ratio(a, b):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Calculate log odds ratio for word frequencies in two corpora.</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    This function compares how often words appear in each corpus</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co">    (accounting for corpus size) and returns a number telling us</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co">    which corpus uses each word more and by how much.</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Positive values = more common in corpus A (Democrats)</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Negative values = more common in corpus B (Republicans)</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co">    Magnitude = how much more (1 = 2×, 2 = 4×, 3 = 8×, etc.)</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters:</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co">    -----------</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co">    a : array-like</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co">        Word counts in corpus A (e.g., Democratic speeches)</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co">    b : array-like</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="co">        Word counts in corpus B (e.g., Republican speeches)</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="co">    --------</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="co">    array-like</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="co">        Log odds ratios (base 2) for each word</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Total corpus sizes</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> np.<span class="bu">sum</span>(a)  <span class="co"># Total words in corpus A</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> np.<span class="bu">sum</span>(b)  <span class="co"># Total words in corpus B</span></span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate proportions (what percentage of each corpus is this word?)</span></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>    prop_a <span class="op">=</span> a <span class="op">/</span> C</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    prop_b <span class="op">=</span> b <span class="op">/</span> D</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate log odds ratio</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Note: We add a tiny constant (1e-10) to avoid mathematical errors when counts are zero</span></span>
<span id="cb33-35"><a href="#cb33-35" aria-hidden="true" tabindex="-1"></a>    lor <span class="op">=</span> np.log2((prop_a <span class="op">+</span> <span class="fl">1e-10</span>) <span class="op">/</span> (prop_b <span class="op">+</span> <span class="fl">1e-10</span>))</span>
<span id="cb33-36"><a href="#cb33-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-37"><a href="#cb33-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lor</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="using-log-odds-ratio-to-see-which-party-uses-each-word" class="level3" data-number="9.6">
<h3 data-number="9.6" class="anchored" data-anchor-id="using-log-odds-ratio-to-see-which-party-uses-each-word"><span class="header-section-number">9.6</span> Using log odds ratio to see which party uses each word</h3>
<div id="75651389" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate log odds ratio</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>freq_table[<span class="st">'log_odds'</span>] <span class="op">=</span> log_odds_ratio(</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    freq_table[<span class="st">'democrat'</span>].values,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    freq_table[<span class="st">'republican'</span>].values</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Add to our content words table too</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>content_words[<span class="st">'log_odds'</span>] <span class="op">=</span> log_odds_ratio(</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    content_words[<span class="st">'democrat'</span>].values,</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    content_words[<span class="st">'republican'</span>].values</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Words most strongly associated with Democrats (positive log odds):"</span>)</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(content_words.nlargest(<span class="dv">15</span>, <span class="st">'log_odds'</span>)[[<span class="st">'lemma'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'log_odds'</span>, <span class="st">'g2'</span>]])</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Words most strongly associated with Republicans (negative log odds):"</span>)</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(content_words.nsmallest(<span class="dv">15</span>, <span class="st">'log_odds'</span>)[[<span class="st">'lemma'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'log_odds'</span>, <span class="st">'g2'</span>]])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Words most strongly associated with Democrats (positive log odds):
          lemma  democrat  republican   log_odds          g2
3123        gun        78           0  23.022742  100.428162
4042   lobbyist        32           0  21.737340   41.201297
3706   internet        30           0  21.644231   38.626216
2085  diversity        28           0  21.544695   36.051135
6756       tech        24           0  21.322303   30.900973
6152     shrink        24           0  21.322303   30.900973
1397   conquest        22           0  21.196772   28.325892
4817  paperwork        22           0  21.196772   28.325892
4238     mental        20           0  21.059268   25.750811
7081         tv        20           0  21.059268   25.750811
6763       teen        18           0  20.907265   23.175730
91         96th        18           0  20.907265   23.175730
6734       tank        18           0  20.907265   23.175730
5617   reinvent        18           0  20.907265   23.175730
2887     french        18           0  20.907265   23.175730

Words most strongly associated with Republicans (negative log odds):
            lemma  democrat  republican   log_odds         g2
6891         tile         0          38 -22.100187  56.626794
53           11th         0          28 -21.659614  41.725006
3090        gross         0          26 -21.552699  38.744648
7036     tribunal         0          22 -21.311691  32.783933
3517        index         0          20 -21.174187  29.803576
244      advisory         0          20 -21.174187  29.803576
5256  prohibition         0          19 -21.100187  28.313397
3028     governor         0          16 -20.852259  23.842860
6279       solely         0          16 -20.852259  23.842860
6808      testing         0          16 -20.852259  23.842860
5564        refer         0          16 -20.852259  23.842860
5442     reaction         0          16 -20.852259  23.842860
6082      seventy         0          16 -20.852259  23.842860
7342     urgently         0          16 -20.852259  23.842860
5455      realism         0          15 -20.759150  22.352682</code></pre>
</div>
</div>
<p>Now we can see the full picture! Look at the output:</p>
<ul>
<li><strong>Positive log odds</strong> (e.g., +2.5) means Democrats use this word more (roughly 2^2.5 ≈ 5-6× more often)</li>
<li><strong>Negative log odds</strong> (e.g., -1.8) means Republicans use this word more (roughly 2^1.8 ≈ 3-4× more often)</li>
</ul>
</section>
<section id="reading-the-results-putting-it-all-together" class="level3" data-number="9.7">
<h3 data-number="9.7" class="anchored" data-anchor-id="reading-the-results-putting-it-all-together"><span class="header-section-number">9.7</span> Reading the results: Putting it all together</h3>
<p>For each word, we now have <strong>three</strong> key numbers:</p>
<ol type="1">
<li><strong>Democrat count / Republican count</strong>: Raw frequencies (affected by corpus size)</li>
<li><strong>Log odds ratio</strong>: Effect size - which party uses it more and by how much</li>
<li><strong>G² value</strong>: Statistical significance - how confident we can be</li>
</ol>
<p><strong>Example interpretation</strong>:</p>
<p>If you see a word with:</p>
<ul>
<li>Log odds = +2.0</li>
<li>G² = 45.3</li>
</ul>
<p>This means: “Democrats use this word about 4× more often than Republicans, and we’re extremely confident (p &lt; 0.001) this is a real pattern, not chance.”</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Best practice: Filter for both significance AND effect size
</div>
</div>
<div class="callout-body-container callout-body">
<p>Not every statistically significant difference is interesting. And not every large difference is reliable.</p>
<p>The most meaningful words are those that pass <strong>three</strong> tests:</p>
<ol type="1">
<li><strong>Statistically significant</strong>: G² &gt; 6.63 (we’re 99% confident it’s real)</li>
<li><strong>Large effect</strong>: |log odds| &gt; 0.5 (at least 40% more frequent in one corpus)</li>
<li><strong>Not too rare</strong>: Appears at least 5 times in both corpora (reliable measurement)</li>
</ol>
<p>Only words that pass all three tests are truly distinctive and reliable.</p>
</div>
</div>
</section>
<section id="finding-the-most-meaningful-differences" class="level3" data-number="9.8">
<h3 data-number="9.8" class="anchored" data-anchor-id="finding-the-most-meaningful-differences"><span class="header-section-number">9.8</span> Finding the most meaningful differences</h3>
<p>Let’s filter our results to find words that are both statistically significant AND show large effects:</p>
<div id="3b6a3cec" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Find meaningful differences - must pass all three tests</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>meaningful <span class="op">=</span> content_words[</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>    (content_words[<span class="st">'g2'</span>] <span class="op">&gt;</span> <span class="fl">6.63</span>) <span class="op">&amp;</span>                    <span class="co"># Test 1: Statistically significant</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    (np.<span class="bu">abs</span>(content_words[<span class="st">'log_odds'</span>]) <span class="op">&gt;</span> <span class="fl">0.5</span>) <span class="op">&amp;</span>       <span class="co"># Test 2: Large effect size</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    (content_words[<span class="st">'democrat'</span>] <span class="op">&gt;</span> <span class="dv">5</span>) <span class="op">&amp;</span>                 <span class="co"># Test 3: Not too rare</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    (content_words[<span class="st">'republican'</span>] <span class="op">&gt;</span> <span class="dv">5</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>].copy()</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Words with significant AND large differences: </span><span class="sc">{</span><span class="bu">len</span>(meaningful)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Top 10 most distinctively Democratic words:"</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(meaningful.nlargest(<span class="dv">10</span>, <span class="st">'log_odds'</span>)[[<span class="st">'lemma'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'log_odds'</span>, <span class="st">'g2'</span>]])</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Top 10 most distinctively Republican words:"</span>)</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(meaningful.nsmallest(<span class="dv">10</span>, <span class="st">'log_odds'</span>)[[<span class="st">'lemma'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'log_odds'</span>, <span class="st">'g2'</span>]])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Words with significant AND large differences: 376

Top 10 most distinctively Democratic words:
           lemma  democrat  republican  log_odds          g2
1278     company       120          14  2.984616   85.637924
4296     minimum        56           8  2.692435   35.797119
2469   everybody        37           6  2.509570   21.825902
1226     college       174          29  2.470043  100.740012
3605  innovation        54          10  2.318039   28.953921
4071         lot        78          15  2.263592   40.605421
282   aggression        80          16  2.207008   40.338351
2955         gas        60          12  2.207008   30.253763
776          big       120          25  2.148115   58.448358
5008      planet        28           6  2.107472   13.304258

Top 10 most distinctively Republican words:
          lemma  democrat  republican  log_odds         g2
1061       cent         6          86 -3.956219  91.520368
5282   property         6          67 -3.596044  66.090068
3765      iraqi         6          48 -3.114917  41.579958
1263  commodity         6          42 -2.922272  34.142816
1743   decrease         6          40 -2.851883  31.708856
826       board         6          40 -2.851883  31.708856
5588     regime        10          61 -2.723727  46.054082
2921   function         8          48 -2.699880  35.895878
4907      pende         6          35 -2.659238  25.744069
1582      court        18         103 -2.631494  74.890387</code></pre>
</div>
</div>
<p>These are the words that truly distinguish Democratic from Republican political rhetoric - they’re both statistically reliable and substantively important.</p>
<hr>
</section>
</section>
<section id="visualizing-differences" class="level2" data-number="10">
<h2 data-number="10" class="anchored" data-anchor-id="visualizing-differences"><span class="header-section-number">10</span> Visualizing differences</h2>
<section id="bar-chart-of-log-odds-ratios" class="level3" data-number="10.1">
<h3 data-number="10.1" class="anchored" data-anchor-id="bar-chart-of-log-odds-ratios"><span class="header-section-number">10.1</span> Bar chart of log odds ratios</h3>
<div id="8b9a100a" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get top 15 for each party</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>top_dem <span class="op">=</span> meaningful.nlargest(<span class="dv">15</span>, <span class="st">'log_odds'</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>top_rep <span class="op">=</span> meaningful.nsmallest(<span class="dv">15</span>, <span class="st">'log_odds'</span>)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>top_both <span class="op">=</span> pd.concat([top_dem, top_rep])</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Sort by log odds for plotting</span></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>top_both <span class="op">=</span> top_both.sort_values(<span class="st">'log_odds'</span>)</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create plot</span></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'#0015BC'</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'#E81B23'</span> <span class="cf">for</span> x <span class="kw">in</span> top_both[<span class="st">'log_odds'</span>]]</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>ax.barh(<span class="bu">range</span>(<span class="bu">len</span>(top_both)), top_both[<span class="st">'log_odds'</span>], color<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(<span class="bu">range</span>(<span class="bu">len</span>(top_both)))</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>ax.set_yticklabels(top_both[<span class="st">'lemma'</span>])</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Log Odds Ratio (negative = Republican, positive = Democrat)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Most Distinctive Words by Party'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Patch</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> [</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">'#0015BC'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'More Democratic'</span>),</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span class="op">=</span><span class="st">'#E81B23'</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'More Republican'</span>)</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>ax.legend(handles<span class="op">=</span>legend_elements, loc<span class="op">=</span><span class="st">'lower right'</span>)</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lab_02_files/figure-html/cell-22-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="scatter-plot-significance-vs-effect-size" class="level3" data-number="10.2">
<h3 data-number="10.2" class="anchored" data-anchor-id="scatter-plot-significance-vs-effect-size"><span class="header-section-number">10.2</span> Scatter plot: Significance vs effect size</h3>
<p>A scatter plot helps us visualize the relationship between effect size (log odds ratio) and statistical significance (G²).</p>
<p>However, we need to be careful about very rare words. Words that appear only once or twice in one corpus but zero times in the other create extreme log odds ratios (dividing by near-zero) with low statistical significance. These are statistical artifacts, not meaningful patterns.</p>
<p>To avoid misleading visualizations, we’ll filter out words that don’t appear at least 5 times in both corpora:</p>
<div id="6a80ad0a" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create scatter plot</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for plotting - remove very rare words that create artifacts</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>plot_data <span class="op">=</span> content_words[</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    (content_words[<span class="st">'democrat'</span>] <span class="op">&gt;=</span> <span class="dv">5</span>) <span class="op">&amp;</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    (content_words[<span class="st">'republican'</span>] <span class="op">&gt;=</span> <span class="dv">5</span>)</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>].copy()</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Color by which party uses word more</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'#0015BC'</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'#E81B23'</span> <span class="cf">for</span> x <span class="kw">in</span> plot_data[<span class="st">'log_odds'</span>]]</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>ax.scatter(plot_data[<span class="st">'log_odds'</span>], plot_data[<span class="st">'g2'</span>],</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>           c<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Add significance threshold line</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>ax.axhline(<span class="fl">6.63</span>, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="st">'p &lt; 0.01'</span>)</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Add effect size threshold lines</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="op">-</span><span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>ax.axvline(<span class="fl">0.5</span>, color<span class="op">=</span><span class="st">'gray'</span>, linestyle<span class="op">=</span><span class="st">':'</span>, linewidth<span class="op">=</span><span class="dv">1</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Log Odds Ratio (negative = Republican, positive = Democrat)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Log-Likelihood (G²)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Effect Size vs Statistical Significance'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Annotate some interesting words</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _, row <span class="kw">in</span> meaningful.head(<span class="dv">10</span>).iterrows():</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>    ax.annotate(row[<span class="st">'lemma'</span>], </span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a>                (row[<span class="st">'log_odds'</span>], row[<span class="st">'g2'</span>]),</span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">8</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a>                xytext<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">5</span>), textcoords<span class="op">=</span><span class="st">'offset points'</span>)</span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lab_02_files/figure-html/cell-23-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>This scatter plot shows the relationship between:</p>
<ul>
<li><strong>X-axis</strong>: Effect size (how different?)</li>
<li><strong>Y-axis</strong>: Statistical significance (how confident?)</li>
</ul>
<p>The most interesting words are in the <strong>upper left</strong> and <strong>upper right</strong> corners - both statistically significant (high G²) and distinctive (large absolute log odds ratio). These are the words that show strong, reliable differences between the two parties.</p>
<p>Words near the bottom (low G²) may have large log odds ratios but aren’t statistically reliable - often because they’re too rare. The horizontal line at G² = 6.63 marks the p &lt; 0.01 significance threshold.</p>
<hr>
</section>
</section>
<section id="named-entity-recognition" class="level2" data-number="11">
<h2 data-number="11" class="anchored" data-anchor-id="named-entity-recognition"><span class="header-section-number">11</span> Named entity recognition</h2>
<p>So far we’ve analyzed individual words (lemmas). But sometimes we’re interested in references to real-world entities:</p>
<ul>
<li><strong>PERSON</strong>: Barack Obama, Hillary Clinton</li>
<li><strong>ORG</strong>: United Nations, Department of Defense</li>
<li><strong>GPE</strong>: America, Iraq, New York</li>
<li><strong>DATE</strong>: tomorrow, 2020, next year</li>
<li><strong>MONEY</strong>: $1 billion, five dollars</li>
</ul>
<p>This is called <strong>Named Entity Recognition (NER)</strong>, and spaCy does it automatically!</p>
<section id="how-ner-works" class="level3" data-number="11.1">
<h3 data-number="11.1" class="anchored" data-anchor-id="how-ner-works"><span class="header-section-number">11.1</span> How NER works</h3>
<p>NER is a classification task:</p>
<ol type="1">
<li>Identify spans of text that might be entities</li>
<li>Classify each span into entity types</li>
<li>Use machine learning models trained on annotated data</li>
</ol>
<p>Modern NER systems use neural networks trained on large corpora of hand-labeled examples.</p>
</section>
<section id="extracting-entities-with-spacy" class="level3" data-number="11.2">
<h3 data-number="11.2" class="anchored" data-anchor-id="extracting-entities-with-spacy"><span class="header-section-number">11.2</span> Extracting entities with spaCy</h3>
<p>Let’s look at entities in a sample speech:</p>
<div id="6964bede" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get one speech</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>sample_speech <span class="op">=</span> dem_speeches.iloc[<span class="dv">0</span>][<span class="st">'transcript'</span>][:<span class="dv">1000</span>]  <span class="co"># First 1000 chars</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Process it</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>sample_doc <span class="op">=</span> nlp(sample_speech)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Display entities</span></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Named entities found:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Entity'</span><span class="sc">:&lt;25}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Type'</span><span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Explanation'</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">65</span>)</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> ent <span class="kw">in</span> sample_doc.ents:</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>ent<span class="sc">.</span>text<span class="sc">:&lt;25}</span><span class="ss"> </span><span class="sc">{</span>ent<span class="sc">.</span>label_<span class="sc">:&lt;15}</span><span class="ss"> </span><span class="sc">{</span>spacy<span class="sc">.</span>explain(ent.label_)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Named entities found:

Entity                    Type            Explanation
-----------------------------------------------------------------
Speaker                   PERSON          People, including fictional
Congress                  ORG             Companies, agencies, institutions, etc.
Americans                 NORP            Nationalities or religious or political groups
Tonight                   TIME            Times smaller than a day
the eighth year           DATE            Absolute or relative dates or periods
the State of the Union    ORG             Companies, agencies, institutions, etc.
Iowa                      GPE             Countries, cities, states
an election season        DATE            Absolute or relative dates or periods
this year                 DATE            Absolute or relative dates or periods
Speaker                   PERSON          People, including fictional
the end of last year      DATE            Absolute or relative dates or periods
this year                 DATE            Absolute or relative dates or periods
tonight                   TIME            Times smaller than a day
the year ahead            DATE            Absolute or relative dates or periods
Don                       PERSON          People, including fictional</code></pre>
</div>
</div>
</section>
<section id="comparing-entity-usage-across-parties" class="level3" data-number="11.3">
<h3 data-number="11.3" class="anchored" data-anchor-id="comparing-entity-usage-across-parties"><span class="header-section-number">11.3</span> Comparing entity usage across parties</h3>
<p>Let’s extract all location entities (GPE = Geo-Political Entity) from both corpora:</p>
<div id="38d751a6" class="cell" data-execution_count="24">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract GPE entities from both corpora</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>dem_locations <span class="op">=</span> [ent.text.lower() <span class="cf">for</span> ent <span class="kw">in</span> dem_doc.ents <span class="cf">if</span> ent.label_ <span class="op">==</span> <span class="st">'GPE'</span>]</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>rep_locations <span class="op">=</span> [ent.text.lower() <span class="cf">for</span> ent <span class="kw">in</span> rep_doc.ents <span class="cf">if</span> ent.label_ <span class="op">==</span> <span class="st">'GPE'</span>]</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Democratic location mentions: </span><span class="sc">{</span><span class="bu">len</span>(dem_locations)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Republican location mentions: </span><span class="sc">{</span><span class="bu">len</span>(rep_locations)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Count frequencies</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>dem_loc_counts <span class="op">=</span> pd.Series(dem_locations).value_counts().reset_index()</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>dem_loc_counts.columns <span class="op">=</span> [<span class="st">'location'</span>, <span class="st">'democrat'</span>]</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>rep_loc_counts <span class="op">=</span> pd.Series(rep_locations).value_counts().reset_index()</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>rep_loc_counts.columns <span class="op">=</span> [<span class="st">'location'</span>, <span class="st">'republican'</span>]</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Merge</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>location_freq <span class="op">=</span> dem_loc_counts.merge(rep_loc_counts, on<span class="op">=</span><span class="st">'location'</span>, how<span class="op">=</span><span class="st">'outer'</span>).fillna(<span class="dv">0</span>)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>location_freq[<span class="st">'democrat'</span>] <span class="op">=</span> location_freq[<span class="st">'democrat'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>location_freq[<span class="st">'republican'</span>] <span class="op">=</span> location_freq[<span class="st">'republican'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Filter for locations mentioned at least 5 times</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>location_freq <span class="op">=</span> location_freq[</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>    (location_freq[<span class="st">'democrat'</span>] <span class="op">&gt;=</span> <span class="dv">5</span>) <span class="op">|</span> (location_freq[<span class="st">'republican'</span>] <span class="op">&gt;=</span> <span class="dv">5</span>)</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a>].copy()</span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Locations mentioned frequently:"</span>)</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(location_freq.head(<span class="dv">15</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Democratic location mentions: 2133
Republican location mentions: 2007

Locations mentioned frequently:
       location  democrat  republican
3   afghanistan        40          57
5        alaska        10           2
7       america       554         701
19    australia         0           6
21      baghdad         0          18
28      belgium         6           2
29       berlin        20           2
38       brazil         4           6
42        burma         6           4
44   california        18          13
45       canada         2          16
52      chicago         4           6
54        china        68          31
57     colombia        14           0
61        congo         6           2</code></pre>
</div>
</div>
</section>
<section id="statistical-comparison-of-locations" class="level3" data-number="11.4">
<h3 data-number="11.4" class="anchored" data-anchor-id="statistical-comparison-of-locations"><span class="header-section-number">11.4</span> Statistical comparison of locations</h3>
<div id="cb97b92f" class="cell" data-execution_count="25">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate G² and log odds for locations</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>location_freq[<span class="st">'g2'</span>] <span class="op">=</span> log_likelihood(</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>    location_freq[<span class="st">'democrat'</span>].values,</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    location_freq[<span class="st">'republican'</span>].values</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>location_freq[<span class="st">'log_odds'</span>] <span class="op">=</span> log_odds_ratio(</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    location_freq[<span class="st">'democrat'</span>].values,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>    location_freq[<span class="st">'republican'</span>].values</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Find significant differences</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a>sig_locations <span class="op">=</span> location_freq[</span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>    (location_freq[<span class="st">'g2'</span>] <span class="op">&gt;</span> <span class="fl">6.63</span>) <span class="op">&amp;</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>    (location_freq[<span class="st">'democrat'</span>] <span class="op">&gt;=</span> <span class="dv">3</span>) <span class="op">&amp;</span></span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>    (location_freq[<span class="st">'republican'</span>] <span class="op">&gt;=</span> <span class="dv">3</span>)</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>].copy()</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Locations with significant usage differences:</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Most Democratic:"</span>)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sig_locations.nlargest(<span class="dv">10</span>, <span class="st">'log_odds'</span>)[[<span class="st">'location'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'log_odds'</span>, <span class="st">'g2'</span>]])</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Most Republican:"</span>)</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(sig_locations.nsmallest(<span class="dv">10</span>, <span class="st">'log_odds'</span>)[[<span class="st">'location'</span>, <span class="st">'democrat'</span>, <span class="st">'republican'</span>, <span class="st">'log_odds'</span>, <span class="st">'g2'</span>]])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Locations with significant usage differences:

Most Democratic:
                         location  democrat  republican  log_odds         g2
96                        germany        24           4  2.539343  15.224309
62                           cuba        16           3  2.369418   9.359102
158                        mexico        16           3  2.369418   9.359102
113                         india        16           4  1.954381   7.335339
238                        russia        36          11  1.664874  13.230245
290  the united states of america        48          20  1.217415  11.011168
284              the soviet union        64          28  1.147026  13.355114
54                          china        68          31  1.087647  13.024438
314                       vietnam        48          22  1.079912   9.087790
7                         america       554         701 -0.385148  22.219891

Most Republican:
                         location  democrat  republican  log_odds         g2
119                          iraq        19         119 -2.692510  83.903263
261                        states        59          88 -0.622408   6.712539
288             the united states       116         163 -0.536366   9.511364
7                         america       554         701 -0.385148  22.219891
314                       vietnam        48          22  1.079912   9.087790
54                          china        68          31  1.087647  13.024438
284              the soviet union        64          28  1.147026  13.355114
290  the united states of america        48          20  1.217415  11.011168
238                        russia        36          11  1.664874  13.230245
113                         india        16           4  1.954381   7.335339</code></pre>
</div>
</div>
</section>
<section id="visualizing-location-mentions" class="level3" data-number="11.5">
<h3 data-number="11.5" class="anchored" data-anchor-id="visualizing-location-mentions"><span class="header-section-number">11.5</span> Visualizing location mentions</h3>
<div id="168a49fa" class="cell" data-execution_count="26">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(sig_locations) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get top locations for each party</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>    top_dem_loc <span class="op">=</span> sig_locations.nlargest(<span class="dv">10</span>, <span class="st">'log_odds'</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>    top_rep_loc <span class="op">=</span> sig_locations.nsmallest(<span class="dv">10</span>, <span class="st">'log_odds'</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    top_loc <span class="op">=</span> pd.concat([top_dem_loc, top_rep_loc]).drop_duplicates().sort_values(<span class="st">'log_odds'</span>)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    colors <span class="op">=</span> [<span class="st">'#0015BC'</span> <span class="cf">if</span> x <span class="op">&gt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'#E81B23'</span> <span class="cf">for</span> x <span class="kw">in</span> top_loc[<span class="st">'log_odds'</span>]]</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    ax.barh(<span class="bu">range</span>(<span class="bu">len</span>(top_loc)), top_loc[<span class="st">'log_odds'</span>], color<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    ax.set_yticks(<span class="bu">range</span>(<span class="bu">len</span>(top_loc)))</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>    ax.set_yticklabels(top_loc[<span class="st">'location'</span>])</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    ax.axvline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(<span class="st">'Log Odds Ratio (negative = Republican, positive = Democrat)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>    ax.set_title(<span class="st">'Geographic Focus: Location Mentions by Party'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Not enough significant location differences in our sample."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="lab_02_files/figure-html/cell-27-output-1.svg" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Other entity types
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can analyze other entity types the same way:</p>
<ul>
<li><strong>PERSON</strong>: Which individuals are mentioned?</li>
<li><strong>ORG</strong>: What organizations are discussed?</li>
<li><strong>DATE</strong>: How are temporal references used?</li>
<li><strong>MONEY</strong>: How are financial amounts discussed?</li>
</ul>
<p>Try exploring these in the exercises!</p>
</div>
</div>
<hr>
</section>
</section>
<section id="summary-and-key-takeaways" class="level2" data-number="12">
<h2 data-number="12" class="anchored" data-anchor-id="summary-and-key-takeaways"><span class="header-section-number">12</span> Summary and key takeaways</h2>
<section id="what-we-learned" class="level3" data-number="12.1">
<h3 data-number="12.1" class="anchored" data-anchor-id="what-we-learned"><span class="header-section-number">12.1</span> What we learned</h3>
<p>Today we covered methods for statistically comparing corpora:</p>
<ol type="1">
<li><strong>Lemmatization</strong> → Reducing words to dictionary forms</li>
<li><strong>Corpus preparation</strong> → Creating contrasting text collections</li>
<li><strong>Log-likelihood (G²)</strong> → Testing statistical significance</li>
<li><strong>Log odds ratio</strong> → Measuring effect size</li>
<li><strong>Named entity recognition</strong> → Extracting references to real-world entities</li>
</ol>
</section>
<section id="key-concepts" class="level3" data-number="12.2">
<h3 data-number="12.2" class="anchored" data-anchor-id="key-concepts"><span class="header-section-number">12.2</span> Key concepts</h3>
<dl>
<dt><strong>Lemmatization</strong></dt>
<dd>
Reducing wordforms to their base dictionary form (lemma)
</dd>
<dt><strong>Contrasting corpora</strong></dt>
<dd>
Collections of texts from different sources for comparison
</dd>
<dt><strong>Log-likelihood (G²)</strong></dt>
<dd>
Statistical test for significance of frequency differences
</dd>
<dt><strong>Log odds ratio</strong></dt>
<dd>
Measure of effect size (how much more frequent)
</dd>
<dt><strong>Named entity</strong></dt>
<dd>
Reference to a real-world entity (person, place, organization)
</dd>
<dt><strong>Effect size vs significance</strong></dt>
<dd>
Significance = confidence; effect size = magnitude
</dd>
</dl>
</section>
<section id="critical-insights" class="level3" data-number="12.3">
<h3 data-number="12.3" class="anchored" data-anchor-id="critical-insights"><span class="header-section-number">12.3</span> Critical insights</h3>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Don’t trust p-values alone!
</div>
</div>
<div class="callout-body-container callout-body">
<p>A word can be:</p>
<ul>
<li><strong>Highly significant</strong> but barely different (large sample)</li>
<li><strong>Highly different</strong> but not significant (rare word)</li>
</ul>
<p>Always report <em>both</em> significance and effect size.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Preprocessing choices matter
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Lemmatize or not?</li>
<li>Remove stop words or not?</li>
<li>Filter by part of speech or not?</li>
</ul>
<p>Each choice affects your results. Make them <strong>explicit</strong> and <strong>justified</strong>.</p>
</div>
</div>
</section>
<section id="statistical-comparison-workflow" class="level3" data-number="12.4">
<h3 data-number="12.4" class="anchored" data-anchor-id="statistical-comparison-workflow"><span class="header-section-number">12.4</span> Statistical comparison workflow</h3>
<ol type="1">
<li><strong>Prepare corpora</strong> → Split data into contrasting groups</li>
<li><strong>Lemmatize</strong> → Reduce morphological variation (if appropriate)</li>
<li><strong>Count frequencies</strong> → Create frequency table</li>
<li><strong>Filter</strong> → Remove very rare words, stop words (if appropriate)</li>
<li><strong>Calculate G²</strong> → Test significance</li>
<li><strong>Calculate log odds</strong> → Measure effect size</li>
<li><strong>Filter meaningful differences</strong> → Both significant AND large</li>
<li><strong>Interpret</strong> → What do the differences tell us?</li>
</ol>
<hr>
</section>
</section>
<section id="exercises" class="level2" data-number="13">
<h2 data-number="13" class="anchored" data-anchor-id="exercises"><span class="header-section-number">13</span> Exercises</h2>
<section id="exercise-1-full-corpus-analysis" class="level3" data-number="13.1">
<h3 data-number="13.1" class="anchored" data-anchor-id="exercise-1-full-corpus-analysis"><span class="header-section-number">13.1</span> Exercise 1: Full corpus analysis</h3>
<p>We used samples for speed in this lab. Now process the <em>full</em> corpora:</p>
<ol type="1">
<li>Process all Democratic and all Republican speeches (not just samples)</li>
<li>Calculate G² and log odds ratio for all lemmas</li>
<li>Identify the 20 most distinctive content words for each party</li>
<li>Create visualizations</li>
</ol>
<p><strong>Note</strong>: This will take 10-15 minutes to process!</p>
</section>
<section id="exercise-2-stop-word-investigation" class="level3" data-number="13.2">
<h3 data-number="13.2" class="anchored" data-anchor-id="exercise-2-stop-word-investigation"><span class="header-section-number">13.2</span> Exercise 2: Stop word investigation</h3>
<p>Investigate whether stop words show political patterns:</p>
<ol type="1">
<li>Filter for <em>only</em> stop words in your frequency table</li>
<li>Calculate G² and log odds ratio</li>
<li>Which stop words differ most between parties?</li>
<li>Can you interpret why? (Think about formality, rhetorical style)</li>
</ol>
</section>
<section id="exercise-3-temporal-comparison" class="level3" data-number="13.3">
<h3 data-number="13.3" class="anchored" data-anchor-id="exercise-3-temporal-comparison"><span class="header-section-number">13.3</span> Exercise 3: Temporal comparison</h3>
<p>Instead of comparing parties, compare time periods:</p>
<ol type="1">
<li>Split speeches into before/after 1970 (or another meaningful date)</li>
<li>Calculate distinctive words for each period</li>
<li>What changes in American political discourse can you observe?</li>
</ol>
</section>
<section id="exercise-4-named-entity-deep-dive" class="level3" data-number="13.4">
<h3 data-number="13.4" class="anchored" data-anchor-id="exercise-4-named-entity-deep-dive"><span class="header-section-number">13.4</span> Exercise 4: Named entity deep dive</h3>
<p>Choose one entity type (PERSON, ORG, or DATE) and:</p>
<ol type="1">
<li>Extract all entities of that type from both corpora</li>
<li>Calculate frequency differences</li>
<li>Identify significant patterns</li>
<li>Interpret: What do these patterns reveal about political priorities?</li>
</ol>
</section>
<section id="exercise-5-part-of-speech-patterns-advanced" class="level3" data-number="13.5">
<h3 data-number="13.5" class="anchored" data-anchor-id="exercise-5-part-of-speech-patterns-advanced"><span class="header-section-number">13.5</span> Exercise 5: Part-of-speech patterns (Advanced)</h3>
<p>Compare parts of speech:</p>
<ol type="1">
<li>Count how often each POS tag appears in each corpus</li>
<li>Do Democrats use more adjectives? Republicans more verbs?</li>
<li>Calculate significance and effect size</li>
<li>What might linguistic differences reveal about rhetorical style?</li>
</ol>
</section>
<section id="exercise-6-creating-your-own-contrasting-corpora" class="level3" data-number="13.6">
<h3 data-number="13.6" class="anchored" data-anchor-id="exercise-6-creating-your-own-contrasting-corpora"><span class="header-section-number">13.6</span> Exercise 6: Creating your own contrasting corpora</h3>
<p>Think of another comparison that interests you in the State of the Union data:</p>
<ul>
<li>War vs peace time presidents</li>
<li>First term vs second term speeches</li>
<li>19th vs 20th vs 21st century</li>
<li>High vs low approval ratings (you’d need to add this data)</li>
</ul>
<p>Design and execute your own corpus comparison study.</p>
<hr>
</section>
</section>
<section id="references-and-further-reading" class="level2" data-number="14">
<h2 data-number="14" class="anchored" data-anchor-id="references-and-further-reading"><span class="header-section-number">14</span> References and further reading</h2>
<section id="academic-papers" class="level3" data-number="14.1">
<h3 data-number="14.1" class="anchored" data-anchor-id="academic-papers"><span class="header-section-number">14.1</span> Academic papers</h3>
<ul>
<li>Dunning, T. (1993). Accurate methods for the statistics of surprise and coincidence. <em>Computational Linguistics</em>, 19(1), 61-74. <a href="https://aclanthology.org/J93-1003.pdf">https://aclanthology.org/J93-1003.pdf</a></li>
<li>Rayson, P., &amp; Garside, R. (2000). Comparing corpora using frequency profiling. <em>Proceedings of the Workshop on Comparing Corpora</em>, 1-6. <a href="https://doi.org/10.3115/1117729.1117730">https://doi.org/10.3115/1117729.1117730</a></li>
<li>Monroe, B. L., Colaresi, M. P., &amp; Quinn, K. M. (2008). Fightin’ words: Lexical feature selection and evaluation for identifying the content of political conflict. <em>Political Analysis</em>, 16(4), 372-403. <a href="https://doi.org/10.1093/pan/mpn018">https://doi.org/10.1093/pan/mpn018</a></li>
</ul>
</section>
<section id="textbooks" class="level3" data-number="14.2">
<h3 data-number="14.2" class="anchored" data-anchor-id="textbooks"><span class="header-section-number">14.2</span> Textbooks</h3>
<ul>
<li>Jurafsky, D., &amp; Martin, J. H. (2023). <em>Speech and Language Processing</em> (3rd ed., draft). Chapter 2 (Regular Expressions, Text Normalization, Edit Distance). <a href="https://web.stanford.edu/~jurafsky/slp3/">https://web.stanford.edu/~jurafsky/slp3/</a></li>
<li>Silge, J., &amp; Robinson, D. (2017). <em>Text Mining with R</em>. Chapter 4 (Relationships between words). <a href="https://www.tidytextmining.com/ngrams.html">https://www.tidytextmining.com/ngrams.html</a></li>
</ul>
</section>
<section id="tutorials" class="level3" data-number="14.3">
<h3 data-number="14.3" class="anchored" data-anchor-id="tutorials"><span class="header-section-number">14.3</span> Tutorials</h3>
<ul>
<li>spaCy documentation on lemmatization: <a href="https://spacy.io/usage/linguistic-features#lemmatization">https://spacy.io/usage/linguistic-features#lemmatization</a></li>
<li>spaCy documentation on NER: <a href="https://spacy.io/usage/linguistic-features#named-entities">https://spacy.io/usage/linguistic-features#named-entities</a></li>
<li>Log-likelihood calculator and explanation: <a href="http://ucrel.lancs.ac.uk/llwizard.html">http://ucrel.lancs.ac.uk/llwizard.html</a></li>
</ul>
</section>
<section id="tools" class="level3" data-number="14.4">
<h3 data-number="14.4" class="anchored" data-anchor-id="tools"><span class="header-section-number">14.4</span> Tools</h3>
<ul>
<li><strong>spaCy</strong>: Industrial-strength NLP library - <a href="https://spacy.io">https://spacy.io</a></li>
<li><strong>NLTK</strong>: Classic Python NLP toolkit - <a href="https://www.nltk.org">https://www.nltk.org</a></li>
<li><strong>Lancaster Stats Tools</strong>: Log-likelihood calculator - <a href="http://ucrel.lancs.ac.uk/llwizard.html">http://ucrel.lancs.ac.uk/llwizard.html</a></li>
</ul>
<hr>
<p><strong>End of Lab 02</strong></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/paskn\.github\.io\/cta-with-python\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>